{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "positive-layer",
   "metadata": {},
   "source": [
    "## Week 6. Neural Nets and backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-environment",
   "metadata": {},
   "source": [
    "In this session we will continue the work we started on neural networks. In particular, in this exercise, you will get to code a neural network from scratch and will be asked to understand and code backpropagation to train the network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-weapon",
   "metadata": {},
   "source": [
    "<img src=\"NNbrainIMage.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "image credit:  [https://appen.com](https://appen.com) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-maintenance",
   "metadata": {},
   "source": [
    "__Exercise 1.__ Let us go back briefly to a simple dataset to make sure we understand how things work. As a first exercise, we will code a one hidden layer neural network that outputs a binary 0/1 variable indicating the class of our data. Throughout this exercise, we will use the notation $z^{\\ell+1} = \\sigma(a^{\\ell+1})$ to denote the output of any neuron from the $(\\ell+1)^{th}$ layer and where $a^{\\ell+1} = \\sum_{k} w_{\\ell+1,k} z_k$ is the combination from the previous layer that is fed to the neuron.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-professional",
   "metadata": {},
   "source": [
    "<img src=\"SingleHiddenLayerNeuralNet.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "image credit:  [MaviccPRP@web.studio](https://maviccprp.github.io) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-competition",
   "metadata": {},
   "source": [
    "We will use the function ['minimize'](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) from scipy. Check the documentation of that function. We will set the 'jac' parameter of the optimizer to 'True', which implies that the (objective) function that we provide as an input should return both the value of the loss and the value of its gradient. \n",
    "\n",
    "For this first exercise, you are asked to write a function $f(W)$ wich takes as arguments a vector $W$ containing all the parameters of your network (as a first step consider building a network with only a few hidden units, in order to make sure the model is working). As indicated above, the function should return (1) the value of the binary cross entropy for the given set of weights and (2) the value of the gradient derived through Backpropagation (as we set the value of 'jac' to True). \n",
    "\n",
    " We will split the writing of your function into several steps. Once you have coded each step, you should gather them together in a single $fun(W)$ body that you will then pass as input to the minimize function. \n",
    "\n",
    "__Exercise 1.a.__ Start Load the data using the lines below and plot it using scatter( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "geographic-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab 6\n",
    "from scipy.optimize import minimize\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "data1 = sio.loadmat(\"pointsClass1Week6.mat\")\n",
    "data2 = sio.loadmat(\"pointsClass2Week6.mat\")\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "data1 = data1[\"pointsClass1Week6\"]\n",
    "data2 = data2[\"pointsClass2Week6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-frank",
   "metadata": {},
   "source": [
    "__Exercise 1.b__ As indicated above, we want to apply the network to the simple binary dataset that you loaded above. We want to build an architecture similar to the one shown above, except that, since we only consider a 2D dataset, we only need 2 inputs. we want our activation function to be all sigmoid. Start by defining the function sigmoid and the gradient of this function. Once you are done, check your derivative. Also make sure you can compute the entrywise sigmoid on any numpy array if the input to your function is a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finished-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    # takes input vector and returns the vector (sigma(x1), sigma(x2), ..., sigma(xn))\n",
    "    # also returns derivative of sigmoid (sigma * (1 - sigma))\n",
    "    \n",
    "    sigmoid = np.divide(1, 1 + np.exp(-x))\n",
    "    return sigmoid, np.multiply(sigmoid, (1 - sigmoid))\n",
    "\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "\n",
    "plt.plot(x, sigmoid(x)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-commissioner",
   "metadata": {},
   "source": [
    "__Exercise 1.c__ Now that we have the sigmoid and its gradient, we will code the loss. As you might remember from previous labs, the MLPClassifier from scikit-learn optimizes the 'log-loss function' (a.k.a Binary cross entropy) which reads for a set of $N$ prototypes $x_i$ with binary $0/1$ targets, \n",
    "\n",
    "$$−\\frac{1}{N}\\sum_{i=1}^N (y_i \\log(p_{W}(x_i))+(1−y_i)\\log(1−p_{W}(x_i))) $$\n",
    "\n",
    "Here the probability $p_{W}(x_i)$ is the output of your network. Instead of minimizing this function directly, we will consider its $\\ell_2$ regularized version\n",
    "\n",
    "$$−\\frac{1}{N}\\sum_{i=1}^N (y_i \\log(p_{W}(x_i))+(1−y_i)\\log(1−p_{W}(x_i)))  + \\lambda \\sum_{j\\in\\text{weights}\\setminus \\text{bias}} W^2_j$$\n",
    "\n",
    "Where the $W_j$ encode the weights. Code that function for a given labeled dataset $X,t$ such as given above, a set of weights stored in the vector $W$ (you can use a list or a dictionnary if you want but ultimately, you will need to store them in a numpy vector for use with the optimization routine).  Note that one typically does not regularize the bias terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns loss value and gradient\n",
    "# inputs: training point x and targets t\n",
    "#         initial weight vector\n",
    "#         alpha is the regularization parameter\n",
    "#         network_size, network_size(k) = num neurons in layer k\n",
    "#\n",
    "# return: value of binary cross entropy loss\n",
    "#         value of gradient\n",
    "\n",
    "def binaryCrossEntropy(x, t, W, alpha, networkSize):\n",
    "    # step 1: forward propagation\n",
    "    NUM_LAYERS = len(networkSize)\n",
    "    \n",
    "    inputsPreviousLayer = len(x)\n",
    "    currentNumNuerons = networkSize[0]\n",
    "    W0 = W[0:currentNumNeurons * (inputsPreviousLayer + 1)] # + 1 for the intercepts\n",
    "    \n",
    "    xTilde = np.vstack((1, x.reshape(-1, 1)))\n",
    "    W0Matrix = np.reshape(W0, (currentNumNeurons, inputsPreviousLayer + 1))\n",
    "    \n",
    "    # preactivation\n",
    "    a = np.matmul(xTilde, W0Matrix)\n",
    "    # postactivation\n",
    "    z = sigmoid(a)[0]\n",
    "    \n",
    "    counter = currentNumNeurons * (inputsPreviousLayer + 1)\n",
    "    \n",
    "    aTotal = np.zeros((np.sum(networkSize), 1))\n",
    "    zTotal = np.zeros((np.sum(networkSize[1 :])sum(networkSize), 1))\n",
    "    \n",
    "    aTotal[0:networkSize[0]] = a\n",
    "    zTotal[0:networkSize[0]] = z\n",
    "    \n",
    "    counter2 = networkSize[0]\n",
    "    \n",
    "    for nn in range(1, NUM_LAYERS):\n",
    "    \n",
    "        inputsPreviousLayer = len(z)\n",
    "        currentNumNuerons = networkSize[nn]\n",
    "        WL = W[counter:counter + currentNumNeurons * (inputsPreviousLayer + 1)] # + 1 for the intercepts\n",
    "        counter += currentNumNeurons * (inputsPreviousLayer + 1)\n",
    "        \n",
    "        zTilde = np.vstack((1, z.reshape(-1, 1)))\n",
    "        WLMatrix = np.reshape(WL, (currentNumNeurons, inputsPreviousLayer + 1))\n",
    "\n",
    "        # preactivation\n",
    "        a = np.matmul(zTilde, WLMatrix)\n",
    "        # postactivation\n",
    "        z = sigmoid(a)[0]\n",
    "        \n",
    "        aTotal[counter2: counter2 + networkSize[nn]] = a\n",
    "        zTotal[counter2: counter2 + networkSize[nn]] = z\n",
    "        \n",
    "        counter2 += networkSize[nn]\n",
    "    \n",
    "    binaryCrossEntropy = -(t * np.log(z) + (1 - t) * np.log(1 - z))\n",
    "    \n",
    "    zOut = z\n",
    "    \n",
    "    # step 2: backward propagation\n",
    "    deltaOut = zOut - target\n",
    "    \n",
    "    numNueronsL = networSize[-1]\n",
    "    numNueronsLMinus1 = networSize[-2]\n",
    "    WeightLastLayer = W[-(numNeuronsL * (numNeuronsLMinus1 + 1)):]\n",
    "    np.reshape(WeightLastLayer, (numberNeuronsLMinus1, numNueronsL))\n",
    "    \n",
    "    # backdrop delta\n",
    "    \n",
    "    tmp = np.matmul(WightLastLayer.T, deltaOut)\n",
    "    \n",
    "    current_ai = aTotal[-networkSize[-1] - networkSize[-2] : -networkSize[-1]]\n",
    "    current_zi = zTotal[-networkSize[-1] - networkSize[-2] : -networkSize[-1]]\n",
    "    \n",
    "    sigmaPrime_ai = sigmoid(a)[1]\n",
    "    \n",
    "    deltaL = np.multiply(tmp, sigmoid(a)[1])\n",
    "    \n",
    "    counter4 = -(numNeuronsL * (numNeuronsLMinus1 + 1))\n",
    "    counter5 = networkSize[-1]-networkSize[-2]\n",
    "    \n",
    "    dL_dwout = np.matmul(deltaL.reshape(-1, 1), current_zi.reshape(-1, 1).T)\n",
    "    \n",
    "    for nn in range(1, NUM_LAYERS):\n",
    "        numNueronsL = networSize[-nn-1]\n",
    "        numNueronsLMinus1 = networSize[-nn-2]\n",
    "        WeightLastLayer = W[-(numNeuronsL * (numNeuronsLMinus1 + 1)) + counter4 : counter4]\n",
    "        np.reshape(WeightLastLayer, (numberNeuronsLMinus1, numNueronsL))\n",
    "\n",
    "        # backdrop delta\n",
    "\n",
    "        tmp = np.matmul(WightLastLayer.T, deltaOut)\n",
    "\n",
    "        current_ai = aTotal[-counter5 - networkSize[-nn-2] : -counter5]\n",
    "        current_zi = zTotal[-counter5 - networkSize[-nn-2] : -counter5]\n",
    "\n",
    "        sigmaPrime_ai = sigmoid(a)[1]\n",
    "\n",
    "        deltaL = np.multiply(tmp, sigmoid(a)[1])\n",
    "        \n",
    "        counter4 += -(numNeuronsL * (numNeuronsLMinus1 + 1))\n",
    "        counter5 += network_size[-nn-2]\n",
    "        \n",
    "    \n",
    "    # return binaryCrossEntropy, gradient\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-palestine",
   "metadata": {},
   "source": [
    "__Exercise 1.d. Towards Backpropagation.__ The example above is relatively simple so that backpropagation is not really needed. Compute the gradient of the Binary cross entropy loss with respect to the weights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-recipient",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
